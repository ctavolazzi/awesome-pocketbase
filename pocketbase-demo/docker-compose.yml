version: '3.8'

services:
  # PocketBase backend database
  pocketbase:
    image: alpine:latest
    container_name: pocketbase-demo
    working_dir: /app
    ports:
      - "8090:8090"
    volumes:
      - ./pb_data:/app/pb_data
      - ./pb_migrations:/app/pb_migrations:ro
    command: sh -c "wget -q https://github.com/pocketbase/pocketbase/releases/download/v0.30.4/pocketbase_0.30.4_linux_amd64.zip -O /tmp/pb.zip && unzip -q /tmp/pb.zip -d /app && chmod +x /app/pocketbase && /app/pocketbase serve --http=0.0.0.0:8090"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8090/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    environment:
      - PB_ENCRYPTION_KEY=${PB_ENCRYPTION_KEY:-}
    networks:
      - pocketbase-network

  # Express API server
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: express-api
    ports:
      - "3030:3030"
    environment:
      # PocketBase connection (use service name in Docker network)
      - PB_BASE_URL=http://pocketbase:8090
      - PB_ADMIN_EMAIL=${PB_ADMIN_EMAIL}
      - PB_ADMIN_PASSWORD=${PB_ADMIN_PASSWORD}

      # Server configuration
      - APP_PORT=3030
      - NODE_ENV=${NODE_ENV:-production}

      # CORS configuration (frontend service URL)
      - ALLOWED_ORIGINS=http://localhost:4173,http://frontend:80

      # Rate limiting
      - RATE_LIMIT_WINDOW_MS=${RATE_LIMIT_WINDOW_MS:-900000}
      - RATE_LIMIT_MAX_REQUESTS=${RATE_LIMIT_MAX_REQUESTS:-100}
      - CREATE_RATE_LIMIT_MAX=${CREATE_RATE_LIMIT_MAX:-10}

      # Optional monitoring
      - SENTRY_DSN=${SENTRY_DSN:-}
      - ENABLE_METRICS=${ENABLE_METRICS:-false}

      # AI Provider configuration
      - AI_PROVIDER=${AI_PROVIDER:-openai}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-5-nano-2025-08-07}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-500}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.8}
      - OLLAMA_URL=${OLLAMA_URL:-http://127.0.0.1:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:1b}
      - AI_INTERVAL_MS=${AI_INTERVAL_MS:-45000}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_API_KEY_FILE=/run/secrets/openai_key
    depends_on:
      pocketbase:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3030/healthz', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    networks:
      - pocketbase-network
    secrets:
      - openai_key

  # Frontend static files served with Nginx
  frontend:
    image: nginx:alpine
    container_name: frontend-demo
    ports:
      - "4173:80"
    volumes:
      - ./public:/usr/share/nginx/html:ro
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - api
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - pocketbase-network

networks:
  pocketbase-network:
    driver: bridge

volumes:
  pb_data:
    driver: local

secrets:
  openai_key:
    file: ./secrets/openai_key.txt
